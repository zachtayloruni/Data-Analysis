{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbwbvevmyZSw"
      },
      "source": [
        "# Image Classification by MLP - Fashion MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxc3hKzGyZSy"
      },
      "source": [
        "In this exercise, we will try to use a neural network on a simple classification task: classifying images of clothes into 10 classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnaPhEYlyZSy"
      },
      "source": [
        "We will first download the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_tvAdqHyZSy",
        "outputId": "6079b53b-1f6e-4f7f-c240-3f49c7d1f927"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "#TODO: load dataset\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "#TODO: Resample the dataset if needed\n",
        "# X_train = ...\n",
        "# y_train = ...\n",
        "# X_test = ...\n",
        "# y_test = ...\n",
        "\n",
        "X_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6oK3usWyZSz"
      },
      "source": [
        "This dataset contains 10 classes:\n",
        "* 0:\tT-shirt/top\n",
        "* 1:\tTrouser\n",
        "* 2:\tPullover\n",
        "* 3:\tDress\n",
        "* 4:\tCoat\n",
        "* 5:\tSandal\n",
        "* 6:\tShirt\n",
        "* 7:\tSneaker\n",
        "* 8:\tBag\n",
        "* 9:\tAnkle boot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftISA6CqyZSz"
      },
      "source": [
        "Now begin by exploring the data. Try to display some images with the associated label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "W0_uCBXNyZS0",
        "outputId": "60d7aa9e-a023-4f93-fb5d-1ff4ef18d4de"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# TODO: Explore the data, display some input images\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "label_class = ['top', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
        "\n",
        "# np.random.seed(0)\n",
        "idx = np.random.randint(X_train.shape[0])\n",
        "\n",
        "plt.imshow(X_train[idx], cmap='gray_r')\n",
        "plt.title(label_class[y_train[idx]])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5VISM_zyZS0"
      },
      "source": [
        "**Before going further**: what methods could you use to perform such a classification task?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTRjUSkxyZS0"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnIPX-N0yZS0"
      },
      "source": [
        "The first method you will try is using neural networks. First step is the data preparation: data rescaling, label preparation.\n",
        "\n",
        "Hint: you can use the Keras function `to_categorical`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "CXG1LTPSyZS0"
      },
      "outputs": [],
      "source": [
        "# TODO: Make the data preparation\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train_cat = to_categorical(y_train, num_classes=10)\n",
        "y_test_cat = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "X_train_norm = X_train/255\n",
        "X_test_norm = X_test/255\n",
        "\n",
        "# TODO: reshape the image data (2D array) into input 1D array for a neural network\n",
        "X_train_norm = X_train_norm.reshape(X_train.shape[0], np.prod(X_train_norm.shape[1:]))\n",
        "X_test_norm = X_test_norm.reshape(X_test.shape[0], np.prod(X_test_norm.shape[1:]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ro5xKj9XyZS1"
      },
      "source": [
        "Next step: model building with Keras. Build your neural network architecture. At first, I would recommend a light architecture: no more than 2 hidden layers, with about 10 units per layer. Put that model into a function, so that you can reuse it later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcK4o6lcyZS1",
        "outputId": "37728071-4532-4823-fac1-5439e44284ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_5 (Dense)             (None, 10)                7850      \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 10)                110       \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 10)                110       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,070\n",
            "Trainable params: 8,070\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# TODO: Build your model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "def my_model(input_dim):\n",
        "    # Create the Sequential object\n",
        "    model = Sequential()\n",
        "\n",
        "    # Add 2 dense layers with 10 neurons each using sigmoid or relu activation\n",
        "    model.add(Dense(10, input_dim=input_dim, activation='sigmoid'))\n",
        "    model.add(Dense(10, activation='sigmoid'))\n",
        "\n",
        "    # Add the output layer with one unit: the predicted result\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    \n",
        "    return model\n",
        "\n",
        "my_model(X_train_norm.shape[1]).summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntoWUVxXyZS1"
      },
      "source": [
        "Now compile and fit your model on your training data. Since this is a multiclass classification, the loss is not `binary_crossentropy` anymore, but `categorical_crossentropy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "scrolled": true,
        "id": "d-8Od6G4yZS1",
        "outputId": "ec4ea3c8-d99b-45ac-8a50-c5528c9022c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 1.9143 - accuracy: 0.4512\n",
            "Epoch 2/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 1.3385 - accuracy: 0.6685\n",
            "Epoch 3/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 1.0050 - accuracy: 0.7218\n",
            "Epoch 4/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.8007 - accuracy: 0.7862\n",
            "Epoch 5/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.6741 - accuracy: 0.8094\n",
            "Epoch 6/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.5987 - accuracy: 0.8198\n",
            "Epoch 7/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.5498 - accuracy: 0.8282\n",
            "Epoch 8/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.5183 - accuracy: 0.8331\n",
            "Epoch 9/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.4948 - accuracy: 0.8384\n",
            "Epoch 10/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.4773 - accuracy: 0.8409\n",
            "Epoch 11/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.4625 - accuracy: 0.8439\n",
            "Epoch 12/100\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.4516 - accuracy: 0.8468\n",
            "Epoch 13/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.4419 - accuracy: 0.8488\n",
            "Epoch 14/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.4345 - accuracy: 0.8500\n",
            "Epoch 15/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.4280 - accuracy: 0.8521\n",
            "Epoch 16/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.4218 - accuracy: 0.8540\n",
            "Epoch 17/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.4165 - accuracy: 0.8553\n",
            "Epoch 18/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.4119 - accuracy: 0.8575\n",
            "Epoch 19/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.4065 - accuracy: 0.8577\n",
            "Epoch 20/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.4035 - accuracy: 0.8589\n",
            "Epoch 21/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3991 - accuracy: 0.8600\n",
            "Epoch 22/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3957 - accuracy: 0.8622\n",
            "Epoch 23/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3928 - accuracy: 0.8634\n",
            "Epoch 24/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3896 - accuracy: 0.8636\n",
            "Epoch 25/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3858 - accuracy: 0.8651\n",
            "Epoch 26/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3833 - accuracy: 0.8661\n",
            "Epoch 27/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3806 - accuracy: 0.8664\n",
            "Epoch 28/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3780 - accuracy: 0.8680\n",
            "Epoch 29/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3759 - accuracy: 0.8690\n",
            "Epoch 30/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3737 - accuracy: 0.8693\n",
            "Epoch 31/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3708 - accuracy: 0.8708\n",
            "Epoch 32/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3684 - accuracy: 0.8712\n",
            "Epoch 33/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3666 - accuracy: 0.8714\n",
            "Epoch 34/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3646 - accuracy: 0.8723\n",
            "Epoch 35/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3623 - accuracy: 0.8729\n",
            "Epoch 36/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3608 - accuracy: 0.8732\n",
            "Epoch 37/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3589 - accuracy: 0.8750\n",
            "Epoch 38/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3575 - accuracy: 0.8746\n",
            "Epoch 39/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3556 - accuracy: 0.8759\n",
            "Epoch 40/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3537 - accuracy: 0.8747\n",
            "Epoch 41/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3528 - accuracy: 0.8759\n",
            "Epoch 42/100\n",
            "469/469 [==============================] - 4s 7ms/step - loss: 0.3510 - accuracy: 0.8771\n",
            "Epoch 43/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.3506 - accuracy: 0.8772\n",
            "Epoch 44/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.3491 - accuracy: 0.8776\n",
            "Epoch 45/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3473 - accuracy: 0.8792\n",
            "Epoch 46/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3456 - accuracy: 0.8783\n",
            "Epoch 47/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3450 - accuracy: 0.8793\n",
            "Epoch 48/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3439 - accuracy: 0.8789\n",
            "Epoch 49/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3417 - accuracy: 0.8810\n",
            "Epoch 50/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3410 - accuracy: 0.8808\n",
            "Epoch 51/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3394 - accuracy: 0.8809\n",
            "Epoch 52/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3388 - accuracy: 0.8810\n",
            "Epoch 53/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3393 - accuracy: 0.8821\n",
            "Epoch 54/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3376 - accuracy: 0.8808\n",
            "Epoch 55/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3361 - accuracy: 0.8821\n",
            "Epoch 56/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3354 - accuracy: 0.8823\n",
            "Epoch 57/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3348 - accuracy: 0.8831\n",
            "Epoch 58/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3343 - accuracy: 0.8828\n",
            "Epoch 59/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3325 - accuracy: 0.8838\n",
            "Epoch 60/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3316 - accuracy: 0.8842\n",
            "Epoch 61/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3310 - accuracy: 0.8839\n",
            "Epoch 62/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3304 - accuracy: 0.8834\n",
            "Epoch 63/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3296 - accuracy: 0.8848\n",
            "Epoch 64/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3290 - accuracy: 0.8849\n",
            "Epoch 65/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3269 - accuracy: 0.8855\n",
            "Epoch 66/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3280 - accuracy: 0.8850\n",
            "Epoch 67/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3250 - accuracy: 0.8858\n",
            "Epoch 68/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3252 - accuracy: 0.8861\n",
            "Epoch 69/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3260 - accuracy: 0.8851\n",
            "Epoch 70/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3237 - accuracy: 0.8862\n",
            "Epoch 71/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3239 - accuracy: 0.8866\n",
            "Epoch 72/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3239 - accuracy: 0.8866\n",
            "Epoch 73/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3224 - accuracy: 0.8867\n",
            "Epoch 74/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3214 - accuracy: 0.8869\n",
            "Epoch 75/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3209 - accuracy: 0.8870\n",
            "Epoch 76/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3205 - accuracy: 0.8871\n",
            "Epoch 77/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3202 - accuracy: 0.8872\n",
            "Epoch 78/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3199 - accuracy: 0.8872\n",
            "Epoch 79/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3189 - accuracy: 0.8870\n",
            "Epoch 80/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3173 - accuracy: 0.8885\n",
            "Epoch 81/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3172 - accuracy: 0.8885\n",
            "Epoch 82/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3168 - accuracy: 0.8883\n",
            "Epoch 83/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3170 - accuracy: 0.8885\n",
            "Epoch 84/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3158 - accuracy: 0.8887\n",
            "Epoch 85/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3156 - accuracy: 0.8888\n",
            "Epoch 86/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3139 - accuracy: 0.8899\n",
            "Epoch 87/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3137 - accuracy: 0.8896\n",
            "Epoch 88/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3140 - accuracy: 0.8895\n",
            "Epoch 89/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3135 - accuracy: 0.8892\n",
            "Epoch 90/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3117 - accuracy: 0.8895\n",
            "Epoch 91/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3120 - accuracy: 0.8900\n",
            "Epoch 92/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3117 - accuracy: 0.8910\n",
            "Epoch 93/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3109 - accuracy: 0.8907\n",
            "Epoch 94/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3111 - accuracy: 0.8912\n",
            "Epoch 95/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3106 - accuracy: 0.8910\n",
            "Epoch 96/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3100 - accuracy: 0.8904\n",
            "Epoch 97/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3100 - accuracy: 0.8914\n",
            "Epoch 98/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3092 - accuracy: 0.8916\n",
            "Epoch 99/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3081 - accuracy: 0.8915\n",
            "Epoch 100/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3088 - accuracy: 0.8916\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0e1aff29e0>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "#https://stackoverflow.com/questions/53014306/error-15-initializing-libiomp5-dylib-but-found-libiomp5-dylib-already-initial\n",
        "# os.environ['KMP_DUPLICATE_LIB_OK']='True' \n",
        "\n",
        "# TODO: Compile and fit your model\n",
        "model = my_model(X_train_norm.shape[1])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train_norm, y_train_cat, epochs=100, batch_size=128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJ0t2VPMyZS2"
      },
      "source": [
        "Once your model has been trained, compute the accuracy (and other metrics if you want) on the train and test dataset.\n",
        "\n",
        "Be careful, Keras returns softmax output (so an array of 10 values between 0 and 1, for which the sum is equal to 1). To compute correctly the accuracy, you have to convert that array into a categorical array with zeros and a 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "HA9kuOvQyZS2",
        "outputId": "44f02ca4-1e95-4709-cb01-b2daaa185a0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy on train with NN: 0.8941666483879089\n",
            "accuracy on test with NN: 0.8543999791145325\n"
          ]
        }
      ],
      "source": [
        "# TODO: Compute the accuracy of your model\n",
        "print('accuracy on train with NN:', model.evaluate(X_train_norm, y_train_cat, verbose=0)[1])\n",
        "print('accuracy on test with NN:', model.evaluate(X_test_norm, y_test_cat, verbose=0)[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ailsIJU6yZS2"
      },
      "source": [
        "What do you think of those results? Can you improve it by changing the number of layers? Of units per layer? The number of epochs? The activation functions?\n",
        "\n",
        "You should try!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwyNjullyZS2"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_Ne05z6yZS3"
      },
      "source": [
        "In order to compare your results with more traditional machine learning methods, you will do this work with another method: a PCA followed by a classification model (of your choice). Of course, you can perform hyperparameter optimization using a gridsearch on that model!\n",
        "\n",
        "Fit your model and display the performances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "w1RRrDvyyZS3"
      },
      "outputs": [],
      "source": [
        "# TODO: Redo the classification with PCA and classification model\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=0.9)\n",
        "\n",
        "pca.fit(X_train_norm)\n",
        "X_train_pca = pca.transform(X_train_norm)\n",
        "X_test_pca = pca.transform(X_test_norm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Gf6WPganyZS3",
        "outputId": "f1f2129e-52c4-49f3-ff5a-6620467de774",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "score with RF on train 1.0\n",
            "score with RF on test 0.8587\n"
          ]
        }
      ],
      "source": [
        "# TODO: use any classifier you want\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "rf.fit(X_train_pca, y_train)\n",
        "\n",
        "print('score with RF on train', rf.score(X_train_pca, y_train))\n",
        "print('score with RF on test', rf.score(X_test_pca, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KjvtBPpyZS3"
      },
      "source": [
        "Are the performances different? Can you explain why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCj8aYMayZS3"
      },
      "source": [
        "If you still have time, you could try to use scikit-learn's `Pipeline` to perform the hyperparameter optimization jointly on the PCA and the classification model. This might improve your performances."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}